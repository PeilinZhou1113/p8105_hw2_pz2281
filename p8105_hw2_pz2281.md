p8105\_hw2\_pz2281
================
Peilin Zhou

## Problem 1

Read in and tidy Mr.Trash Wheel data

``` r
trash_wheel_df = 
  readxl::read_excel("./data/Trash_Wheel.xlsx", range = "A2:N406") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = round(sports_balls))
```

Import and tidy precipitation data for 2018 and 2019

``` r
pre_2018 = 
  readxl::read_excel("./data/Trash_Wheel.xlsx", sheet = 5, range = "A2:B14") %>%
  janitor::clean_names() %>% 
  mutate(year = "2018")

pre_2019 = 
  readxl::read_excel("./data/Trash_Wheel.xlsx", sheet = 4, range = "A2:B8") %>% 
  janitor::clean_names() %>% 
  mutate(year = "2019")
```

Combine data

``` r
 tidy_pre = 
  bind_rows(pre_2018,pre_2019) %>% 
  relocate(year) %>% 
  mutate(month = month.name[month])
```

Data Summaries

The Mr.Trash Wheel dataset contains litter data for total of 344
dumpsters through 6 years. There are 14 variables in this dataset. For
all of the dumpsters, the average number of plastic bottles they
received through the five-year span is 1873 and the average number of
cigarette butts is 3.0754^{4}. The amount of total litter that that
trash wheel had collected in 5 years is 1122.45 tons.

The number of observation is 12 for the 2018 precipitation data and 6
for the 2019 data. Both datasets have 3 variables, including month,
year, and precipitation amount in inches. The total amount of
precipitation in 2018 was 70.33 inches and the average amount was
5.8608333 inches. The total amount of precipitation in 2019 (data for 6
months) was 16.67 inches and the median was 3.34 inches. The conmbined
dataset contains precipitation data for both 2018 and 2019. The total
amount of precipitation was 87 and the average was 4.8333333.

## Problem 2

Import and tidy pols-month data

``` r
pols_month =
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, into = c("year", "month","day"), sep = "-") %>% 
  mutate(month = as.numeric(month)) %>% 
  mutate(month = month.name[month]) %>% 
  mutate(president = ifelse(prez_gop == 1, "gop", "dem")) %>% 
  select(-prez_dem,-prez_gop,-day)
```

Import and tidy snp data

``` r
snp_df = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  mutate(date = lubridate::mdy(date)) %>% 
  separate(date, into = c("year","month", "day"), sep = "-") %>%
  mutate(month = as.numeric(month)) %>%
  mutate(month = month.name[month]) %>% 
  arrange(year,month) %>% 
  relocate(year,month) %>% 
  select(-day)
```

Import and tidy unemployment data

``` r
unemp_df = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment") %>% 
  mutate(month = match(month,month.abb)) %>% 
  mutate(month = month.name[month]) %>% 
  janitor::clean_names() %>% 
  mutate(year = as.character(year))
```

Merge snp\_df to pols\_month and then merge unemp\_df into the merged
data using `left_join`

``` r
pols_snp_df = left_join(pols_month, snp_df, by = c("year", "month"))

merge_df = left_join(pols_snp_df, unemp_df, by = c("year", "month"))
```

Data Summaries

The pols\_month dataset contains 822 observations and 9 variables. It is
documenting the number of national politicians who are democratic or
republican throughout 68 years. The key variables include the number of
republican senators, governors, representatives, and president, as well
as the number of democratic senators, governors, representatives, and
president at each year and associated month. The data documented the
information through January, 1947 to June, 2015.

The snp dataset contains 787 observations and 3 variables. it is related
to the Standard & Poorâ€™s stock market index which is a representative
measure of stock market as a whole within given dates. The year range is
99 years from 1969 to 2068. The key variable in this dataset is close
which specifies the closing values of the S&P stock index on the
associated date (year-month). The average closing value is 474.8887404.

The unemployment dataset contains 816 observations and 3 variables. It
is related to the unemployment rate within given dates. The year range
is 67 from 1948 to 2015. The key variable in this dataset is
unemployment which specifies the percentage of unemployment on
associated data (year-month). The average unemployment rate is 5.83%.
The highest unemployment rate is 10.8% and the lowest is 2.5%.

The merge\_df is a merged dataframe from the three datasets above
(snp\_df and unemp\_df merged into pols\_month). The keys to merge the
set were year and month. It contains 822 observations and 11 variables,
which is the conbination of the previous variables in pols\_month with
closing market index and unemployment rate with the associated date from
the pols\_month data. Since two dataframes were merged into pols\_month,
the range of year maintains the same as that in pols\_month.

## Problem 3

read in and tidy the data.

``` r
pop_names = 
   read_csv("./data/Popular_Baby_Names.csv") %>% 
   janitor::clean_names() %>% 
   mutate(ethnicity = gsub(" ", "_", ethnicity)) %>% 
   mutate(gender = tolower(gender), ethnicity = tolower(ethnicity)) %>% 
   mutate(ethnicity = recode(ethnicity, "asian_and_pacific_islander" = "asian_and_paci", "white_non_hispanic" = "white_non_hisp", "black_non_hispanic" = "black_non_hisp"))
```

Check out the names in ethnicity to find the redundant changes.

``` r
unique(pop_names$ethnicity)
```

    ## [1] "asian_and_paci" "black_non_hisp" "hispanic"       "white_non_hisp"

Then, recode categorical values in ethnicity in the previous pipeline.
